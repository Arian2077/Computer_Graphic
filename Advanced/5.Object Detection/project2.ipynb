{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b6c769d",
   "metadata": {},
   "source": [
    "## Mini Project #5 - Object Detection using SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sift_detector(new_image, image_template):\n",
    "    # Function that compares input image to template\n",
    "    # It then returns the number of SIFT matches between them\n",
    "    \n",
    "    image1 = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
    "    image2 = image_template\n",
    "    \n",
    "    # Create SIFT detector object\n",
    "    sift = cv2.SIFT()\n",
    "\n",
    "    # Obtain the keypoints and descriptors using SIFT\n",
    "    keypoints_1, descriptors_1 = sift.detectAndCompute(image1, None)\n",
    "    keypoints_2, descriptors_2 = sift.detectAndCompute(image2, None)\n",
    "\n",
    "    # Define parameters for our Flann Matcher\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 3)\n",
    "    search_params = dict(checks = 100)\n",
    "\n",
    "    # Create the Flann Matcher object\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    # Obtain matches using K-Nearest Neighbor Method\n",
    "    # the result 'matchs' is the number of similar matches found in both images\n",
    "    matches = flann.knnMatch(descriptors_1, descriptors_2, k=2)\n",
    "\n",
    "    # Store good matches using Lowe's ratio test\n",
    "    good_matches = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            good_matches.append(m) \n",
    "\n",
    "    return len(good_matches)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Load our image template, this is our reference image\n",
    "image_template = cv2.imread('images/box_in_scene.png', 0) \n",
    "\n",
    "while True:\n",
    "\n",
    "    # Get webcam images\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Get height and width of webcam frame\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # Define ROI Box Dimensions\n",
    "    top_left_x = width / 3\n",
    "    top_left_y = (height / 2) + (height / 4)\n",
    "    bottom_right_x = (width / 3) * 2\n",
    "    bottom_right_y = (height / 2) - (height / 4)\n",
    "    \n",
    "    # Draw rectangular window for our region of interest   \n",
    "    cv2.rectangle(frame, (top_left_x,top_left_y), (bottom_right_x,bottom_right_y), 255, 3)\n",
    "    \n",
    "    # Crop window of observation we defined above\n",
    "    cropped = frame[bottom_right_y:top_left_y , top_left_x:bottom_right_x]\n",
    "    \n",
    "    # Flip frame orientation horizontally\n",
    "    frame = cv2.flip(frame,1)\n",
    "    \n",
    "    # Get number of SIFT matches\n",
    "    matches = sift_detector(cropped, image_template)\n",
    "\n",
    "    # Display status string showing the current no. of matches \n",
    "    cv2.putText(frame,str(matches),(450,450), cv2.FONT_HERSHEY_COMPLEX, 2,(0,255,0),1)\n",
    "    \n",
    "    # Our threshold to indicate object deteciton\n",
    "    # We use 10 since the SIFT detector returns little false positves\n",
    "    threshold = 10\n",
    "    \n",
    "    # If matches exceed our threshold then object has been detected\n",
    "    if matches > threshold:\n",
    "        cv2.rectangle(frame, (top_left_x,top_left_y), (bottom_right_x,bottom_right_y), (0,255,0), 3)\n",
    "        cv2.putText(frame,'Object Found',(50,50), cv2.FONT_HERSHEY_COMPLEX, 2 ,(0,255,0), 2)\n",
    "    \n",
    "    cv2.imshow('Object Detector using SIFT', frame)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5f375",
   "metadata": {},
   "source": [
    "این کد یک سیستم تشخیص شیء با استفاده از الگوریتم SIFT و OpenCV پیاده‌سازی می‌کند. در ادامه توضیح بخش‌های مختلف کد آورده شده است:سیستم تشخیص شیء با استفاده از الگوریتم SIFT و OpenCV پیاده‌سازی می‌کند. در ادامه توضیح بخش‌های مختلف کد آورده شده است:\n",
    "\n",
    "- ابتدا کتابخانه‌های مورد نیاز (`cv2` و `numpy`) وارد می‌شوند.- ابتدا کتابخانه‌های مورد نیاز (`cv2` و `numpy`) وارد می‌شوند.\n",
    "- تابع `sift_detector` دو تصویر را دریافت می‌کند و تعداد نقاط کلیدی مشابه بین آن‌ها را با استفاده از الگوریتم SIFT محاسبه می‌کند.- تابع `sift_detector` دو تصویر را دریافت می‌کند و تعداد نقاط کلیدی مشابه بین آن‌ها را با استفاده از الگوریتم SIFT محاسبه می‌کند.\n",
    "    - تصاویر به خاکستری تبدیل می‌شوند.\n",
    "    - شیء SIFT ساخته می‌شود و نقاط کلیدی و توصیف‌گرها استخراج می‌شوند.ا استخراج می‌شوند.\n",
    "    - با استفاده از Flann Matcher، نقاط کلیدی مشابه بین دو تصویر پیدا می‌شوند.ویر پیدا می‌شوند.\n",
    "    - با استفاده از تست Lowe، فقط تطابق‌های خوب نگه داشته می‌شوند.- با استفاده از تست Lowe، فقط تطابق‌های خوب نگه داشته می‌شوند.\n",
    "    - تعداد تطابق‌های خوب بازگردانده می‌شود.\n",
    "- دوربین وبکم فعال می‌شود و تصویر مرجع (template) بارگذاری می‌شود. تصویر مرجع (template) بارگذاری می‌شود.\n",
    "- در یک حلقه بی‌نهایت: یک حلقه بی‌نهایت:\n",
    "    - تصویر جدید از وبکم خوانده می‌شود.ی‌شود.\n",
    "    - ابعاد تصویر گرفته می‌شود و یک ناحیه ROI (مستطیل) در تصویر مشخص می‌شود.ته می‌شود و یک ناحیه ROI (مستطیل) در تصویر مشخص می‌شود.\n",
    "    - این ناحیه برش داده می‌شود.    - این ناحیه برش داده می‌شود.\n",
    "    - تصویر افقی برعکس می‌شود.\n",
    "    - تعداد تطابق‌های SIFT بین ناحیه برش‌خورده و تصویر مرجع محاسبه می‌شود.ی‌شود.\n",
    "    - تعداد تطابق‌ها روی تصویر نمایش داده می‌شود.\n",
    "    - اگر تعداد تطابق‌ها از یک آستانه (۱۰) بیشتر باشد، شیء شناسایی شده و مستطیل سبز و متن \"Object Found\" نمایش داده می‌شود.    - اگر تعداد تطابق‌ها از یک آستانه (۱۰) بیشتر باشد، شیء شناسایی شده و مستطیل سبز و متن \"Object Found\" نمایش داده می‌شود.\n",
    "    - تصویر خروجی نمایش داده می‌شود و با فشردن کلید Enter حلقه متوقف می‌شود.ن کلید Enter حلقه متوقف می‌شود.\n",
    "- در پایان، دوربین و پنجره‌ها آزاد و بسته می‌شوند.‌ها آزاد و بسته می‌شوند.\n",
    "\n",
    "این کد برای شناسایی یک شیء خاص در تصویر زنده وبکم با استفاده از ویژگی‌های SIFT کاربرد دارد.ر زنده وبکم با استفاده از ویژگی‌های SIFT کاربرد دارد.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd02b6e0",
   "metadata": {},
   "source": [
    "## Object Detection using ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def ORB_detector(new_image, image_template):\n",
    "    # Function that compares input image to template\n",
    "    # It then returns the number of ORB matches between them\n",
    "    \n",
    "    image1 = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create ORB detector with 1000 keypoints with a scaling pyramid factor of 1.2\n",
    "    orb = cv2.ORB(1000, 1.2)\n",
    "\n",
    "    # Detect keypoints of original image\n",
    "    (kp1, des1) = orb.detectAndCompute(image1, None)\n",
    "\n",
    "    # Detect keypoints of rotated image\n",
    "    (kp2, des2) = orb.detectAndCompute(image_template, None)\n",
    "\n",
    "    # Create matcher \n",
    "    # Note we're no longer using Flannbased matching\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Do matching\n",
    "    matches = bf.match(des1,des2)\n",
    "\n",
    "    # Sort the matches based on distance.  Least distance\n",
    "    # is better\n",
    "    matches = sorted(matches, key=lambda val: val.distance)\n",
    "\n",
    "    return len(matches)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Load our image template, this is our reference image\n",
    "image_template = cv2.imread('images/box_in_scene.png', 0) \n",
    "# image_template = cv2.imread('images/kitkat.jpg', 0) \n",
    "\n",
    "while True:\n",
    "\n",
    "    # Get webcam images\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Get height and width of webcam frame\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # Define ROI Box Dimensions (Note some of these things should be outside the loop)\n",
    "    top_left_x = width / 3\n",
    "    top_left_y = (height / 2) + (height / 4)\n",
    "    bottom_right_x = (width / 3) * 2\n",
    "    bottom_right_y = (height / 2) - (height / 4)\n",
    "    \n",
    "    # Draw rectangular window for our region of interest\n",
    "    cv2.rectangle(frame, (top_left_x,top_left_y), (bottom_right_x,bottom_right_y), 255, 3)\n",
    "    \n",
    "    # Crop window of observation we defined above\n",
    "    cropped = frame[bottom_right_y:top_left_y , top_left_x:bottom_right_x]\n",
    "\n",
    "    # Flip frame orientation horizontally\n",
    "    frame = cv2.flip(frame,1)\n",
    "    \n",
    "    # Get number of ORB matches \n",
    "    matches = ORB_detector(cropped, image_template)\n",
    "    \n",
    "    # Display status string showing the current no. of matches \n",
    "    output_string = \"Matches = \" + str(matches)\n",
    "    cv2.putText(frame, output_string, (50,450), cv2.FONT_HERSHEY_COMPLEX, 2, (250,0,150), 2)\n",
    "    \n",
    "    # Our threshold to indicate object deteciton\n",
    "    # For new images or lightening conditions you may need to experiment a bit \n",
    "    # Note: The ORB detector to get the top 1000 matches, 350 is essentially a min 35% match\n",
    "    threshold = 350\n",
    "    \n",
    "    # If matches exceed our threshold then object has been detected\n",
    "    if matches > threshold:\n",
    "        cv2.rectangle(frame, (top_left_x,top_left_y), (bottom_right_x,bottom_right_y), (0,255,0), 3)\n",
    "        cv2.putText(frame,'Object Found',(50,50), cv2.FONT_HERSHEY_COMPLEX, 2 ,(0,255,0), 2)\n",
    "    \n",
    "    cv2.imshow('Object Detector using ORB', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4743c",
   "metadata": {},
   "source": [
    "این کد یک سیستم تشخیص شیء با استفاده از الگوریتم ORB و OpenCV پیاده‌سازی می‌کند. در ادامه بخش‌های مختلف کد توضیح داده شده است:سیستم تشخیص شیء با استفاده از الگوریتم ORB و OpenCV پیاده‌سازی می‌کند. در ادامه بخش‌های مختلف کد توضیح داده شده است:\n",
    "\n",
    "- ابتدا کتابخانه‌های مورد نیاز (`cv2` و `numpy`) وارد می‌شوند.- ابتدا کتابخانه‌های مورد نیاز (`cv2` و `numpy`) وارد می‌شوند.\n",
    "- تابع `ORB_detector` دو تصویر را دریافت می‌کند و تعداد نقاط کلیدی مشابه بین آن‌ها را با استفاده از الگوریتم ORB محاسبه می‌کند:- تابع `ORB_detector` دو تصویر را دریافت می‌کند و تعداد نقاط کلیدی مشابه بین آن‌ها را با استفاده از الگوریتم ORB محاسبه می‌کند:\n",
    "    - تصویر ورودی به خاکستری تبدیل می‌شود.\n",
    "    - یک شیء ORB با ۱۰۰۰ نقطه کلیدی ساخته می‌شود.\n",
    "    - نقاط کلیدی و توصیف‌گرها برای هر دو تصویر استخراج می‌شوند.ند.\n",
    "    - یک BFMatcher با معیار Hamming ساخته می‌شود.- یک BFMatcher با معیار Hamming ساخته می‌شود.\n",
    "    - تطابق بین توصیف‌گرها انجام و بر اساس فاصله مرتب می‌شود.‌شود.\n",
    "    - تعداد تطابق‌ها بازگردانده می‌شود.    - تعداد تطابق‌ها بازگردانده می‌شود.\n",
    "- دوربین وبکم فعال می‌شود و تصویر مرجع (template) بارگذاری می‌شود.\n",
    "- در یک حلقه بی‌نهایت:\n",
    "    - تصویر جدید از وبکم خوانده می‌شود.    - تصویر جدید از وبکم خوانده می‌شود.\n",
    "    - ابعاد تصویر گرفته می‌شود و یک ناحیه ROI (مستطیل) در تصویر مشخص می‌شود.ه ROI (مستطیل) در تصویر مشخص می‌شود.\n",
    "    - این ناحیه برش داده می‌شود.\n",
    "    - تصویر افقی برعکس می‌شود.    - تصویر افقی برعکس می‌شود.\n",
    "    - تعداد تطابق‌های ORB بین ناحیه برش‌خورده و تصویر مرجع محاسبه می‌شود.‌خورده و تصویر مرجع محاسبه می‌شود.\n",
    "    - تعداد تطابق‌ها روی تصویر نمایش داده می‌شود.\n",
    "    - اگر تعداد تطابق‌ها از یک آستانه (۳۵۰) بیشتر باشد، شیء شناسایی شده و مستطیل سبز و متن \"Object Found\" نمایش داده می‌شود.    - اگر تعداد تطابق‌ها از یک آستانه (۳۵۰) بیشتر باشد، شیء شناسایی شده و مستطیل سبز و متن \"Object Found\" نمایش داده می‌شود.\n",
    "    - تصویر خروجی نمایش داده می‌شود و با فشردن کلید Enter حلقه متوقف می‌شود.یش داده می‌شود و با فشردن کلید Enter حلقه متوقف می‌شود.\n",
    "- در پایان، دوربین و پنجره‌ها آزاد و بسته می‌شوند.\n",
    "\n",
    "این کد برای شناسایی یک شیء خاص در تصویر زنده وبکم با استفاده از ویژگی‌های ORB کاربرد دارد.این کد برای شناسایی یک شیء خاص در تصویر زنده وبکم با استفاده از ویژگی‌های ORB کاربرد دارد.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
